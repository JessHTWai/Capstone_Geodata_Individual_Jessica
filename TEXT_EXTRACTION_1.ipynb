{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": { 
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUdKsi1_v8J6",
        "outputId": "cceb4cd1-b229-48e4-9e7f-94bff7acba29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfminer.six\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pdfminer.six\n",
            "Successfully installed pdfminer.six-20250506\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfminer.six"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_pages\n",
        "from pdfminer.layout import LTTextContainer\n",
        "import re\n",
        "import os\n",
        "import openai\n",
        "import time\n",
        "import ast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EJSNSNJk7Z8",
        "outputId": "4bbb41f5-e592-45aa-c9d0-410ab0e988f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pages_text(pdf_path):\n",
        "    pages = []\n",
        "    for page_layout in extract_pages(pdf_path):\n",
        "        lines = []\n",
        "        for element in page_layout:\n",
        "            if isinstance(element, LTTextContainer):\n",
        "                lines.append(element.get_text())\n",
        "        pages.append('\\n'.join(lines))\n",
        "    return pages\n",
        "\n",
        "def is_toc_page(text):\n",
        "    if \"table of contents\" in text or \"contents\" in text:\n",
        "        return True\n",
        "    if re.search(r'\\.{5,}', text) and re.search(r'\\d{1,3}\\s*$', text, re.MULTILINE):\n",
        "        return True\n",
        "    if sum(1 for l in text.split('\\n') if re.match(r'.*\\d{1,3}\\s*$', l)) > 5:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def is_ack_page(text):\n",
        "    return \"acknowledgement\" in text or \"acknowledgments\" in text\n",
        "\n",
        "def is_declaration_page(text):\n",
        "    return \"declaration\" in text\n",
        "\n",
        "def is_main_section_start(text):\n",
        "    return bool(re.search(\n",
        "        r'\\b(?:1\\.|chapter\\s*1)[:\\s-]*introduction\\b|\\bintroduction\\b',\n",
        "        text, re.IGNORECASE\n",
        "    ))\n",
        "\n",
        "def remove_empty_lines(text):\n",
        "    return \"\\n\".join(line for line in text.splitlines() if line.strip())\n",
        "\n",
        "def remove_references(text):\n",
        "    # Trims text at first \"references\" heading (case-insensitive)\n",
        "    pattern = re.compile(r\"(?im)^.*references.*$\", re.MULTILINE)\n",
        "    match = pattern.search(text)\n",
        "    if match:\n",
        "        return text[:match.start()].strip()\n",
        "    return text\n",
        "\n",
        "def pdf_to_text(pdf_path):\n",
        "    pages = extract_pages_text(pdf_path)\n",
        "    body_pages = pages[1:]  # Remove the first page (cover)\n",
        "    filtered_pages = []\n",
        "    skip_mode = None\n",
        "    for pg in body_pages:\n",
        "        pg_lower = pg.lower()\n",
        "        if skip_mode == 'toc':\n",
        "            if is_main_section_start(pg_lower):\n",
        "                skip_mode = None\n",
        "            elif is_toc_page(pg_lower):\n",
        "                continue\n",
        "            else:\n",
        "                skip_mode = None\n",
        "        elif skip_mode == 'ack':\n",
        "            if is_main_section_start(pg_lower):\n",
        "                skip_mode = None\n",
        "            elif is_ack_page(pg_lower):\n",
        "                continue\n",
        "            else:\n",
        "                skip_mode = None\n",
        "        elif skip_mode == 'dec':\n",
        "            if is_main_section_start(pg_lower):\n",
        "                skip_mode = None\n",
        "            elif is_declaration_page(pg_lower):\n",
        "                continue\n",
        "            else:\n",
        "                skip_mode = None\n",
        "        if skip_mode is None:\n",
        "            if is_toc_page(pg_lower):\n",
        "                skip_mode = 'toc'\n",
        "                continue\n",
        "            elif is_ack_page(pg_lower):\n",
        "                skip_mode = 'ack'\n",
        "                continue\n",
        "            elif is_declaration_page(pg_lower):\n",
        "                skip_mode = 'dec'\n",
        "                continue\n",
        "        filtered_pages.append(pg)\n",
        "\n",
        "    pages_left = len(filtered_pages)\n",
        "\n",
        "    main_body_text = \"\\n\\n\".join(filtered_pages)\n",
        "    main_body_text = remove_empty_lines(main_body_text)\n",
        "    main_body_text = remove_references(main_body_text)\n",
        "    return main_body_text, pages_left\n",
        "\n",
        "def process_pdf_folder(folder_path, output_txt_folder=None, csv_report_path=None):\n",
        "    import pandas as pd\n",
        "    results = []\n",
        "    if output_txt_folder:\n",
        "        os.makedirs(output_txt_folder, exist_ok=True)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            pdf_path = os.path.join(folder_path, filename)\n",
        "            print(f\"Processing: {filename}\")\n",
        "            try:\n",
        "                text, num_pages = pdf_to_text(pdf_path)\n",
        "                results.append({\"filename\": filename, \"pages_left\": num_pages})\n",
        "                if output_txt_folder:\n",
        "                    txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "                    txt_path = os.path.join(output_txt_folder, txt_filename)\n",
        "                    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                        f.write(text)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {filename}: {e}\")\n",
        "    # Report of pages\n",
        "    if csv_report_path:\n",
        "        pd.DataFrame(results).to_csv(csv_report_path, index=False)\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    folder = \"/content/drive/MyDrive/data_pdf\"\n",
        "    out_folder = \"/content/drive/MyDrive/Data3_txt\"\n",
        "    report_csv = \"/content/drive/MyDrive/pdf_page_report.csv\"\n",
        "    process_pdf_folder(folder, out_folder, report_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJgWxASF6-aW",
        "outputId": "08b781e2-95b8-4b0a-8c52-9f4cb1e66fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 2015_Masurel_phd.pdf\n",
            "Processing: 2008_MATABANE_FE3.pdf\n",
            "Processing: 2012_Lindsay_thesis_final.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P6' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P0' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P1' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P2' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P3' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P4' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P5' is an invalid float value\n",
            "WARNING:pdfminer.pdfinterp:Cannot set gray non-stroke color because /'P6' is an invalid float value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 2007_Tshibubudze_THE MARKOYE FAULT_2007.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sentence_paragraphs(text, sentences_per_paragraph=6):\n",
        "    # Split into sentences using regex (simple version)\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    sentences = [s.strip() for s in sentences if s.strip()]\n",
        "    paragraphs = []\n",
        "    for i in range(0, len(sentences), sentences_per_paragraph):\n",
        "        para = \" \".join(sentences[i:i+sentences_per_paragraph])\n",
        "        paragraphs.append(para)\n",
        "    return paragraphs\n"
      ],
      "metadata": {
        "id": "3dPFUqPi85Li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"/content/drive/MyDrive/Data3_txt/2008_MATABANE_FE3.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "paragraphs = text_to_sentence_paragraphs(text, sentences_per_paragraph=6)\n",
        "print(f\"Found {len(paragraphs)} paragraphs.\")\n",
        "print(\"\\nSample paragraph:\\n\", paragraphs[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW1tD-Gk886L",
        "outputId": "f27b46af-b757-49f1-ba70-91fa57ffc318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 84 paragraphs.\n",
            "\n",
            "Sample paragraph:\n",
            " Abstract \n",
            "The  FE3  open  casts  (Sadiola  goldfield,  Mali)  are  operated  by  the  by  the  Société \n",
            "d’Exploitation des Mines d’Or de Sadiola S.A.. The open casts comprise meta-sedimentary \n",
            "rocks  that  can  be  divided  into  five  units;  lower  slump  facies,  upper  slump  facies,  siltstone-\n",
            "greywacke  unit,  greywacke  unit  and  a  laterite  profile. The  lower  slump  facies  consists  of \n",
            "siltstone beds and is characterised by massive chaotic slump folds and olistoliths. The upper \n",
            "slump  facies  consists  of  greywacke-siltstone  beds  and  is  characterised  by  turbidite  beds, \n",
            "slump  folds  and  fluid  escape  structures. The  siltstone-greywacke  unit  is  characterised  by \n",
            "turbidite beds. The greywacke unit is carbonaceous.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sentence_paragraphs(text, sentences_per_paragraph=6):\n",
        "    # Basic sentence splitter (works for most scientific writing)\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
        "    sentences = [s.strip() for s in sentences if s.strip()]\n",
        "    paragraphs = []\n",
        "    for i in range(0, len(sentences), sentences_per_paragraph):\n",
        "        para = \" \".join(sentences[i:i+sentences_per_paragraph])\n",
        "        paragraphs.append(para)\n",
        "    return paragraphs\n",
        "\n",
        "def folder_txts_to_paragraphs(folder_path, sentences_per_paragraph=6):\n",
        "    file_paragraphs = {}\n",
        "    for fname in os.listdir(folder_path):\n",
        "        if fname.lower().endswith(\".txt\"):\n",
        "            file_path = os.path.join(folder_path, fname)\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                text = f.read()\n",
        "            paras = text_to_sentence_paragraphs(text, sentences_per_paragraph=sentences_per_paragraph)\n",
        "            file_paragraphs[fname] = paras\n",
        "    return file_paragraphs\n"
      ],
      "metadata": {
        "id": "u3rMbTlxNea9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/MyDrive/Data3_txt\"\n",
        "file_paragraphs = folder_txts_to_paragraphs(folder_path, sentences_per_paragraph=6)\n",
        "\n",
        "test_files = list(file_paragraphs.keys())[:3]\n",
        "for fname in test_files:\n",
        "    print(f\"\\n--- {fname} ---\")\n",
        "    for i, para in enumerate(file_paragraphs[fname][:5]):\n",
        "        print(f\"Paragraph {i+1}: {para[:300]}{'...' if len(para)>300 else ''}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuCVvxqrNrJc",
        "outputId": "b85ea388-7592-451e-9398-8b67acb3ca6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 2015_Masurel_phd.txt ---\n",
            "Paragraph 1: ii \n",
            "A vous Maman, Papa, Manon, Arthur \n",
            "“Happiness is only real when shared” \n",
            "(Christopher Johnson McCandless, Into the wild) \n",
            "iii \n",
            "iv \n",
            "Abstract \n",
            "The  Paleoproterozoic  belts  of  West  Africa  are  the  fastest-growing  gold \n",
            "production \n",
            "in \n",
            "the  world. The  Kédougou-Kénieba \n",
            "inlier  (KKI)  represen...\n",
            "\n",
            "Paragraph 2: Deposit-scale investigations indicate that gold deposits of the Sadiola-Yatela district are \n",
            "primarily  hosted  by \n",
            "impure  metacarbonates  and, \n",
            "to  a \n",
            "lesser  extent,  detrital \n",
            "metasedimentary  rocks  (e.g.,  wacke,  arenite,  siltstone,  and  argillite)  and  Eburnean \n",
            "granitoids. The  presence ...\n",
            "\n",
            "Paragraph 3: The D2 and \n",
            "D3  events  represent  a  transpressional  deformation  continuum  that  was  associated  with \n",
            "voluminous calc-alkaline magmatism. This deformation continuum marks the principal \n",
            "imprint  of  the  Eburnean  orogeny  (ca. 2115-2060  Ma)  in  the  district. Eburnean \n",
            "granitoids exposed in...\n",
            "\n",
            "Paragraph 4: Despite the commonalities, gold mineralisation in the Sadiola-Yatela district \n",
            "exhibits  three  distinct  styles  defined  on  the  basis  of  contrasted  ore  and  alteration \n",
            "paragenesis. The  three gold mineralisation styles  are typified by  the Sadiola Hill-style \n",
            "Au-As-Sb  mineralisation,  the...\n",
            "\n",
            "Paragraph 5: vi \n",
            "Sanogo, Fousseyni Samake, Monzon Traoré, Yakouba Koné, and Timothé Sogoba, for \n",
            "their warm welcome and making every fieldwork period great. I  acknowledge  the  Australian  Microscopy  and  Microanalysis  Research  Facility \n",
            "at  the  Centre  for  Microscopy,  Characterisation  and  Analysis;  a ...\n",
            "\n",
            "\n",
            "--- 2008_MATABANE_FE3.txt ---\n",
            "Paragraph 1: Abstract \n",
            "The  FE3  open  casts  (Sadiola  goldfield,  Mali)  are  operated  by  the  by  the  Société \n",
            "d’Exploitation des Mines d’Or de Sadiola S.A.. The open casts comprise meta-sedimentary \n",
            "rocks  that  can  be  divided  into  five  units;  lower  slump  facies,  upper  slump  facies,  siltstone-...\n",
            "\n",
            "Paragraph 2: The  sediments  of  the  lower  slump  facies,  upper  slump  facies  and  the  siltstone-greywacke \n",
            "unit  are  interpreted  to  have  been  deposited  in  a  seismically-active  turbulent  environment, \n",
            "with mass transport and debris flow along a delta-front. The greywacke unit is interpreted to \n",
            "r...\n",
            "\n",
            "Paragraph 3: The primary gold mineralisation is associated with hydrothermal chlorite-\n",
            "sericite  alteration  which  is  related  to  hydrothermal  fluids  that  are  interpreted  to  have \n",
            "originated  from  the  granodiorite  dykes. Secondary  placer  gold  mineralisation  occur  in \n",
            "palaeochannels  that  cross-...\n",
            "\n",
            "Paragraph 4: The  geology  and  metallogenic  setting  of  the  FE3  open  cast  has  not  been  investigated, \n",
            "mapped  or  researched  to  date. Therefore  the  relationship  between  the  stratigraphy, \n",
            "structures  and  intrusive  rocks  is  not  known,  but  it  is  considered  by  Sadiola  mine  geology \n",
            "tea...\n",
            "\n",
            "Paragraph 5: The Sadiola goldfield \n",
            "is located 80 km west of the capital city of Bamako on the western border of Senegal and \n",
            "Mali  (Fig. 1). Mali  is  a  landlocked,  Sahel  country  and  is  mostly  semi-desert  or  desert. The \n",
            "climate ranges from sub-tropical in the south to arid in the north. The country is...\n",
            "\n",
            "\n",
            "--- 2012_Lindsay_thesis_final.txt ---\n",
            "Paragraph 1: iv\n",
            "Abstract\n",
            "3D modelling aims to solve geological problems, but these are always underdetermined and require \n",
            "prediction to produce geologically reasonable results. There are a series of related issues associated \n",
            "with 3D modelling techniques that require analysis, including geophysical ambiguity, s...\n",
            "\n",
            "Paragraph 2: The effect of geological uncertainty \n",
            "on 3D model architecture is analysed with a set of ‘geodiversity’ metrics, a collection of analytical \n",
            "techniques that characterise each model within the model suite geometrically and geophysically. Geometrical metrics include: depth and volume of a geological u...\n",
            "\n",
            "Paragraph 3: This thesis demonstrates a set of techniques that better \n",
            "describe the geological problem and provide guidance to geophysical inversion procedures. We demonstrate stratigraphic variability, geodiversity and inversion techniques on two case studies: \n",
            "the Gippsland Basin, a mature oil and gas prospect...\n",
            "\n",
            "Paragraph 4: While we all never managed \n",
            "to be in the same room at the same time, your willingness to respond to my requests and flights of \n",
            "fancy is greatly appreciated. I hope that we can all share a celebratory drink at some stage in the \n",
            "near future. Special thanks go to Laurent for persisting with organisin...\n",
            "\n",
            "Paragraph 5: Several organisations and groups have provided much needed support and assistance. Thank you to \n",
            "those who are and were at Intrepid Geophysics; Des FitzGerald, Asbjørn Christensen, Ray Seikel \n",
            "and  Stewart  Hore  for  ongoing  support  with  Geomodeller  and  other  topics  of  interest. Thanks \n",
            "als...\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
